{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 pipeline\n",
    "\n",
    "using pipeline, code can be simpled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyu/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.515137790197567"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#without pipeline\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "raw_boston = datasets.load_boston()\n",
    "\n",
    "x = raw_boston.data\n",
    "y = raw_boston.target\n",
    "\n",
    "# split traiging / test data\n",
    "x_tn, x_te, y_tn, y_te = train_test_split(x,y,random_state=7) \n",
    "\n",
    "#normalized scaling\n",
    "std_scale = StandardScaler()\n",
    "x_tn_std = std_scale.fit_transform(x_tn)\n",
    "x_te_std = std_scale.transform(x_te)\n",
    "\n",
    "#Learning\n",
    "clf_linear = LinearRegression()\n",
    "clf_linear.fit(x_tn_std,y_tn)\n",
    "\n",
    "#prediction\n",
    "pred_linear = clf_linear.predict(x_te_std)\n",
    "\n",
    "#Evaluation\n",
    "mean_squared_error(y_te, pred_linear)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onyu/.local/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29.515137790197567"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using pipeline\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "raw_boston = datasets.load_boston()\n",
    "\n",
    "x = raw_boston.data\n",
    "y = raw_boston.target\n",
    "\n",
    "# split traiging / test data\n",
    "x_tn, x_te, y_tn, y_te = train_test_split(x,y,random_state=7) \n",
    "\n",
    "#pipeline\n",
    "linear_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('linear_regression', LinearRegression())\n",
    "    ])\n",
    "\n",
    "#Learning\n",
    "linear_pipeline.fit(x_tn,y_tn)\n",
    "\n",
    "#prediction\n",
    "pred_linear = linear_pipeline.predict(x_te)\n",
    "\n",
    "#Evaluation\n",
    "mean_squared_error(y_te, pred_linear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4 Grid Search\n",
    "\n",
    ":머신러닝 과정에서 관심있는 매개 변수들을 대상으로 학습가능하도록 만드는 방식을 의미\n",
    "관심있는 하이퍼파라미터 후보군을 가지고 모델 성능 비교, 최적의 하이퍼파라미터 선정가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "#knn k 최근접 이웃 알고리즘에서 가장 적합한 k값 찾기\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# import flower data\n",
    "raw_iris = datasets.load_iris()\n",
    "\n",
    "#feature/target\n",
    "x = raw_iris.data\n",
    "y = raw_iris.target\n",
    "\n",
    "#split training/test data\n",
    "\n",
    "x_tn, x_te, y_tn, y_te = train_test_split(x, y, random_state=0)\n",
    "\n",
    "#normalized scaling\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(x_tn)\n",
    "x_tn_std = std_scale.transform(x_tn)\n",
    "x_te_std = std_scale.transform(x_te)\n",
    "\n",
    "best_accuracy = 0\n",
    "\n",
    "for k in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    clf_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    clf_knn.fit(x_tn_std,y_tn)\n",
    "    knn_pred = clf_knn.predict(x_te_std)\n",
    "    accuracy = accuracy_score(y_te,knn_pred)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        final_k = k\n",
    "    \n",
    "print(final_k)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#7.6.2 classification분류 문제에서의 성능 평가\n",
    "\n",
    "# ACCURACY\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = [0,2,1,3]\n",
    "y_true = [0,1,2,3]\n",
    "print(accuracy_score(y_true,y_pred))\n",
    "print(accuracy_score(y_true, y_pred, normalize=False))\n",
    "\n",
    "#default : normalize = True  정확도가 0에서 1 사이값으로 나타남. 1에 가까울 수록 정확도가 높음\n",
    "#normalize = False 는 예측값과 실젯값이 일치하는 빈도수 출력\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7.6.2 classification분류 문제에서의 성능 평가\n",
    "\n",
    "# F1 score : precision과 recall의 조화 평균값. 1에 가까울수록 높은 성능. (이건 코드 없음)\n",
    "\n",
    "# confustion metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = [2,0,2,2,0,1]\n",
    "y_pred = [0,0,2,2,0,2]\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n",
    "#클래스 별로 예측값과 실젯값의 빈도를 행렬 형태로 출력. 잘 모르겠음. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.67      1.00      0.80         2\n",
      "     class 1       0.00      0.00      0.00         1\n",
      "     class 2       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.56      0.50      0.49         5\n",
      "weighted avg       0.67      0.60      0.59         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7.6.2 classification분류 문제에서의 성능 평가\n",
    "\n",
    "#classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_true = [0,1,2,2,0]\n",
    "y_pred = [0,0,2,1,0]\n",
    "target_names = ['class 0','class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.375\n",
      "0.9486081370449679\n"
     ]
    }
   ],
   "source": [
    "#7.6.3 regression model performance evaluation\n",
    "\n",
    "# MAE mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "y_true = [3,-0.5,2,7]\n",
    "y_pred = [2.5,0.0,2,8]\n",
    "print(mean_absolute_error(y_true, y_pred))\n",
    "\n",
    "# MSE mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = [3,-0.5,2,7]\n",
    "y_pred = [2.5,0.0,2,8]\n",
    "print(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# r2 SCORE\n",
    "from sklearn.metrics import r2_score\n",
    "y_true = [3,-0.5,2,7]\n",
    "y_pred = [2.5,0.0,2,8]\n",
    "print(r2_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.6.4 clustering model performance evaluation\n",
    "\n",
    "#silhoueete score : 서로 다른 군집이 얼마나 잘 분리되는지 나타내는 지표. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
